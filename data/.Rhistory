ls()
?ls()
read.table(file.choose(),sep=",",header=TRUE)
read.table(file.choose(),sep=",",header=TRUE)
t = table(Class)
install.packages(c("dplyr", "ggplot2", "nycflights13"))
read.table(file.choose(),sep=",",header=TRUE)
install.packages(c("dplyr", "ggplot2", "nycflights13"))
dim(flights)
library(nycflights13)
dim(flights)
head(flights)
tail(flights)
filter(flights, month==1, day==1)
filter(flights,month==1,day==1)
f=filter(flights,month==1,day==1)
f=filter(flights,month==1,day==1)
install.packages("dplyr")
install.packages("dplyr")
install.packages("nycflights13")
install.packages("nycflights13")
library(nycflights13)
f=filter(flights,month==1,day==1)
x <- c(0,0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0)
# Calculating and plotting entropy for the binary case
?log2
# define function to measure the performance of a classification model
entropy <- function(p){
ifelse(p==0 | p==1, 0, -(p*log2(p)+(1-p)*log2(1-p)))
}
entropy(0.5)
entropy(0.99999)
entropy(1)
entropy(0)
x <- c(0,0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0)
y <- entropy(x)
plot(x,y, type="b", xlab="p", ylab="Entropy")
IG <- function(p, p1, p2, prop1){
entropy(p) - (prop1*entropy(p1)+(1-prop1)*entropy(p2))
}
IG(0.53, 0.92, 0.24, 0.43)
# We will now use the rpart package for decision tree classification
pkgs <- c("rpart", "rpart.plot", "party", "randomForest", "e1071")
#install.packages(pkgs,lib="C:/Rick/R/Rlib",depend=TRUE)
install.packages(pkgs, depend=TRUE)
?install.packages
?sample
?table
?rpart
# CUSTOMIZE DATA FILE: Define website that provides data file
loc <- "http://archive.ics.uci.edu/ml/machine-learning-databases/"
# CUSTOMIZE DATA FILE: Define data file
ds <- "breast-cancer-wisconsin/breast-cancer-wisconsin.data"
# Paste converts its arguments (via as.character) to character strings, and concatenates them (separating them by the string given by sep)
url <- paste(loc, ds, sep="")
# CUSTOMIZE DATA FILE: read.table reads a file in table format and creates a data frame from it
breast <- read.table(url, sep=",", header=FALSE, na.strings="?")
# CUSTOMIZE DATA FILE: Define column names
# CUSTOMIZE DATA FILE: The categorical dependent variable is called target
names(breast) <- c("ID", "clumpThickness", "sizeUniformity",
"shapeUniformity", "marginalAdhesion",
"singleEpithelialCellSize", "bareNuclei",
"blandChromatin", "normalNucleoli", "mitosis", "target")
# Define data frame containing all columns except first column
df <- breast[-1]
# CUSTOMIZE DATA FILE: factor relabels categorical values for a categorical variable
# CUSTOMIZE DATA FILE: The categorical dependent variable is called target
df$target <- factor(df$target, levels=c(2,4),
labels=c("benign", "malignant"))
# Define seed for random number generator
set.seed(1234)
# sample takes a random sample of the specified size from the elements of x
train <- sample(nrow(df), 0.7*nrow(df))
# Define training data frame using random sample of observations
df.train <- df[train,]
# Define validation data frame using all observations not in training data frame
df.validate <- df[-train,]
# CUSTOMIZE DATA: Table counts the observations for each categorical value of target
# CUSTOMIZE DATA: The categorical dependent variable is called target
table(df.train$target)
table(df.validate$target)
# Decision Tree
# library loads add-on packages
#library(rpart,lib="C:/Rick/R/Rlib")
library(rpart)
# Define seed for random number generator
set.seed(1234)
# Fit a recursive partitioning model
# CUSTOMIZE DATA: the first parameter target specifies the categorical dependent variable
# CUSTOMIZE DATA: The categorical dependent variable is called target
dtree <- rpart(target ~ ., data=df.train, method="class",
parms=list(split="information"))
# Summarize the decision tree including decision nodes and leaf nodes
# The decision tree nodes are described row by row, then left to right
summary(dtree)
# Display decision tree.  The true values follow the left branches.
plot(dtree);text(dtree)
# Display decision tree complexity parameter table which is a matrix of information on the optimal prunings based on a complexity parameter
# Identify CP that corresponds to the lowest xerror
dtree$cptable
# Plot complexity parameter table
plotcp(dtree)
# Determine CP that corresponds to the lowest xerror
# Get index of CP with lowest xerror
opt <- which.min(dtree$cptable[,"xerror"])
# get its CP value
cp <- dtree$cptable[opt, "CP"]
# Prune decision tree to decrease overfitting
dtree.pruned <- prune(dtree, cp)
# Display pruned decision tree.  The true values follow the left branches.
plot(dtree.pruned);text(dtree.pruned)
# class displays the object class
class(dtree$cptable)
# names displays the names of an object
names(dtree)
#library(rpart.plot,lib="C:/Rick/R/Rlib")
library(rpart.plot)
# Determine proportion of categorical dependent variable
# CUSTOMIZE DATA: The categorical dependent variable is called target
table(df.train$target)/nrow(df.train)
# prp plots an rpart model
prp(dtree.pruned, type=2, extra=104, fallen.leaves=TRUE, main="Decision Tree")
# predict evaluates the application of a model to a data frame
dtree.pred <- predict(dtree.pruned, df.validate, type="class")
# define classification matrix
# CUSTOMIZE DATA: The categorical dependent variable is called target
dtree.perf <- table(df.validate$target, dtree.pred, dnn=c("Actual", "Predicted"))
dtree.perf
# Random Forest
#library(randomForest,lib="C:/Rick/R/Rlib")
library(randomForest)
# Define seed for random number generator
set.seed(1234)
# Fit a random forest model
# The na.action=na.roughfix option replaces missing values on numeric variables with column medians and missing values on categorical variables with the modal category for that variable
# CUSTOMIZE DATA: The categorical dependent variable is called target
forest <- randomForest(target ~ ., data=df.train,
na.action=na.roughfix,
importance=TRUE)
# Display a summary for a random forest model
forest
# Display variable importance measures for a random forest model
importance(forest, type=2)
# predict evaluates the application of a model to a data frame
forest.pred <- predict(forest, df.validate)
# define classification matrix
# CUSTOMIZE DATA: The categorical dependent variable is called target
forest.perf <- table(df.validate$target, forest.pred,
dnn=c("Actual", "Predicted"))
forest.perf
source('C:/Users/Ryan Luu/Desktop/MSBA SUMMER \'19/BANA200A/Project 4/Classification Rev4.R')
#if you are on mac, change the setwd
setwd("~/GitHub/OCRugVARKS/data")
data <- read.csv("bank-full.csv", TRUE, ';')
#Packages
library(randomForest)
library(caret)
library(ggplot2)
library(dplyr)
library(lubridate)
library(scales)
#Visualize the Data
View(data)
data$month_num[data$month == 'jan'] = 1
data$month_num[data$month == 'feb'] = 2
data$month_num[data$month == 'mar'] = 3
data$month_num[data$month == 'apr'] = 4
data$month_num[data$month == 'may'] = 5
data$month_num[data$month == 'jun'] = 6
data$month_num[data$month == 'jul'] = 7
data$month_num[data$month == 'aug'] = 8
data$month_num[data$month == 'sep'] = 9
data$month_num[data$month == 'oct'] = 10
data$month_num[data$month == 'nov'] = 11
data$month_num[data$month == 'dec'] = 12
data$x <- paste(data$month_num,data$day, "2008")
data$x <- mdy(data$x)
data2008 <- data[1:27729,]
View(data2008)
data2009 <- data[27730:42952,]
data2010 <- data[42953:45211,]
#if you are on mac, change the setwd
setwd("~/GitHub/OCRugVARKS/data")
data <- read.csv("bank-full.csv", TRUE, ';')
#Packages
library(randomForest)
library(caret)
library(ggplot2)
library(lubridate)
library(scales)
library(gridExtra)
library(DMwR)
#View Data
head(data)
str(data)
#Color Code
colory <- "#56a8e8"
colorn <- "grey75"
#View imbalance of data$y
ggplot(data, aes(y, fill = y)) + geom_bar() +
theme_minimal()+
scale_fill_manual(values = c(colorn,colory)) +
guides(fill = guide_legend(reverse = TRUE)) +
geom_text(stat = 'count',aes(label =..count.., vjust = -0.2)) +
theme(panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),plot.background=element_blank()) +
labs(title = "Subcription to a Term Deposit",
x = "Response",
y = "Frequency",
fill = "Subscription")
#Data Partitioning
#Create two new dataframe, data_yes has all of the obs with y=yes, data_no has all of the obs with y=no
data_yes <- data[ which(data$y=='yes'),]
data_no <- data[ which(data$y=='no'),]
set.seed(1234)
ind <- sample(2,nrow(data_no), replace = TRUE, prob = c(0.7,0.3))
train <- data_no[ind==1,]
test <- data_no[ind==2,]
ind <- sample(2,nrow(data_yes), replace = TRUE, prob = c(0.7,0.3))
train1 <- data_yes[ind==1,]
test1 <- data_yes[ind==2,]
train <- rbind(train, train1)
test <- rbind(test, test1)
#Train the Model
rf <- randomForest(y~., data=train)
print(rf)
#Prediction & Confusion Matrix - train data
p1 <- predict(rf, train)
confusionMatrix(p1, train$y)
#Prediction & Confusion Matrix - test data
p2 <- predict(rf, test)
confusionMatrix(p2, test$y)
#Variable importance plot
varImpPlot(rf)
#Look at Duration
summary(data_yes$duration)
summary(data_no$duration)
ggplot(data, aes(y, duration/60)) +
geom_boxplot() +
theme_minimal() +
theme(axis.line=element_blank(),legend.position="bottom",
panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),plot.background=element_blank()) +
ylim(0, 90) +
xlab(NULL) +
ylab("Call Duration in Minutes") +
labs(title = "Call Duration Boxplot by 'Yes' and 'No' Groups", fill = "Subscribe Bank Term Depsoit")
#Convert Month into month number
data$month_num[data$month == 'jan'] = 1
data$month_num[data$month == 'feb'] = 2
data$month_num[data$month == 'mar'] = 3
data$month_num[data$month == 'apr'] = 4
data$month_num[data$month == 'may'] = 5
data$month_num[data$month == 'jun'] = 6
data$month_num[data$month == 'jul'] = 7
data$month_num[data$month == 'aug'] = 8
data$month_num[data$month == 'sep'] = 9
data$month_num[data$month == 'oct'] = 10
data$month_num[data$month == 'nov'] = 11
data$month_num[data$month == 'dec'] = 12
#Create a date column by combining month number and day. 2008 is a dummy year since observations did not include the year of the obs.
data$date <- paste(data$month_num,data$day, "2008")
data$date <- mdy(data$date)
#New dataframe by year
data2008 <- data[1:27729,]
data2009 <- data[27730:42952,]
data2010 <- data[42953:45211,]
#Plot observations by year
#Observations in 2008
m1 <- ggplot(data2008, aes(date, fill = y)) +
geom_histogram(binwidth = 2,colour = "white", size = 0.1,show.legend = FALSE) +
theme_minimal() +
scale_fill_manual(values = c(colorn,colory)) +
scale_x_date(date_labels="%b",date_breaks  ="1 month") +
theme(axis.line=element_blank(),
panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),plot.background=element_blank()) +
xlab(NULL) +
ylab("2008 Observations") +
labs(fill = "Subscribe Bank Term Depsoit")
#Observations in 2009
m2 <- ggplot(data2009, aes(date, fill = y)) +
geom_histogram(binwidth = 2,colour = "white", size = 0.1,show.legend = FALSE) +
theme_minimal() +
scale_fill_manual(values = c(colorn,colory)) +
scale_x_date(date_labels="%b",date_breaks  ="1 month") +
theme(axis.line=element_blank(),
panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),plot.background=element_blank()) +
ylim(0, 1500) +
xlab(NULL) +
ylab("2009 Observations") +
labs(fill = "Subscribe Bank Term Depsoit")
#Observations in 2010
m3 <- ggplot(data2010, aes(date, fill = y)) +
geom_histogram(binwidth = 2,colour = "white", size = 0.1,show.legend = FALSE) +
theme_minimal() +
scale_fill_manual(values = c(colorn,colory)) +
scale_x_date(date_labels="%b",date_breaks  ="1 month") +
theme(axis.line=element_blank(),
panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),plot.background=element_blank()) +
ylim(0, 1000) +
xlab(NULL) +
ylab("2010 Observations") +
labs(fill = "Subscribe Bank Term Depsoit")
#Total Observations
ggplot(data, aes(date, fill = y)) +
geom_histogram(binwidth = 2,colour = "white", size = 0.1) +
theme_minimal() +
scale_fill_manual(values = c(colorn,colory)) +
guides(fill = guide_legend(reverse = TRUE)) +
scale_x_date(date_labels="%b",date_breaks  ="1 month") +
theme(axis.line=element_blank(), legend.position="top",
panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),plot.background=element_blank()) +
xlab(NULL) +
ylab("Total Observations") +
labs(fill = "Subscription")
#Plot graphs 2008, 2009, 2010
grid.arrange(m1, m2, m3, nrow = 3)
#Investigate Age and Subscription
ggplot(data, aes(age, fill = y)) + geom_histogram(binwidth = 2,colour = "white", size = 0.1) +
theme_minimal() + scale_fill_manual(values = c(colorn,colory)) +
labs(title = NULL,
x = "Age",
y = "Observations",
fill = "Subscription") +
guides(fill = guide_legend(reverse = TRUE)) +
theme(axis.line=element_blank(),
panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),plot.background=element_blank())
#Look at age and subscription ratio
ggplot(data, aes(age, fill = y)) + geom_histogram(position = "fill",binwidth = 2,colour = "white", size = 0) +
theme_minimal() + scale_fill_manual(values = c(colorn,colory)) +
labs(title = NULL,
x = "Age",
y = "Yes / No Ratio",
fill = "Subscription") +
xlim(18,95) +
guides(fill = guide_legend(reverse = TRUE)) +
theme(axis.line=element_blank(),
panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),plot.background=element_blank())
#Create three new data frame by age groups
data_age1 <- data[which(data$age>=18 & data$age <30),]
data_age2 <- data[which(data$age>=30 & data$age <60),]
data_age3 <- data[which(data$age>60),]
#Plot frequency of term deposit by age group
p1 <- ggplot(data_age1, aes(y, fill = y)) +
geom_bar(show.legend = FALSE) +
theme_minimal()+
scale_fill_manual(values = c(colorn,colory)) +
guides(fill = guide_legend(reverse = TRUE)) +
theme(axis.line=element_blank(),
axis.title.y=element_blank(),
panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),plot.background=element_blank()) +
labs(title = "Age Group 18-29",
x = NULL,
y = "Frequency",
fill = "Did the client subscribe a term deposit?")
p2 <- ggplot(data_age2, aes(y, fill = y)) +
geom_bar(show.legend = FALSE) +
theme_minimal()+
scale_fill_manual(values = c(colorn,colory)) +
guides(fill = guide_legend(reverse = TRUE)) +
theme(axis.line=element_blank(),
axis.title.y=element_blank(),
panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),plot.background=element_blank()) +
labs(title = "Age Group 30-59",
x = NULL,
y = NULL,
fill = "Did the client subscribe a term deposit?")
p3 <- ggplot(data_age3, aes(y, fill = y)) +
geom_bar(show.legend = FALSE) +
theme_minimal()+
scale_fill_manual(values = c(colorn,colory)) +
guides(fill = guide_legend(reverse = TRUE)) +
theme(axis.line=element_blank(),
panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),plot.background=element_blank()) +
labs(title = "Age Group 60+",
x = NULL,
y = NULL,
fill = "Did the client subscribe a term deposit?")
grid.arrange(p1, p2, p3, nrow = 3)
#Improving randomForest Model with synthetic data; remove columns irrelevant in predicting subscription
data_c <- subset(data, select =-c(duration, month, day, date, month_num))
table(data_c$y)
newData_c <- SMOTE(y ~ ., data_c, perc.over = 600,perc.under=100)
table(newData_c$y)
set.seed(1234)
ind <- sample(2,nrow(newData_c), replace = TRUE, prob = c(0.7,0.3))
train <- newData_c[ind==1,]
test <- newData_c[ind==2,]
#Training the new model
rf <- randomForest(y~., data=train)
print(rf)
#Plot new confusion matrix - train data
p1 <- predict(rf, train)
confusionMatrix(p1, train$y)
#Plot new confusion matrix - test data
p2 <- predict(rf, test)
confusionMatrix(p2, test$y)
#Variable importance plot
varImpPlot(rf)
#Partial Dependence plot
partialPlot(rf, train, campaign, "yes")
partialPlot(rf, train, poutcome, "yes")
#Evaluating Relationship between age, balance, and subscription
g1 <- ggplot(data_age1, aes(age, balance)) +
geom_point(aes(colour=factor(y)),show.legend = FALSE, alpha = 4/10) +
scale_color_manual(values = c(colorn,colory)) +
theme(axis.line=element_blank(), plot.title = element_text(size = 16), plot.subtitle = element_text(size = 10),
panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),plot.background=element_blank()) +
ylim(0, 100000) +
theme(legend.position="top") +
labs(title = "Relationship between Age, Balance, and Subscription",
subtitle="Blue and Grey represents observations with and without subscription, respectively.",
x = "Age Group 1")
g2 <- ggplot(data_age2, aes(age, balance)) +
geom_point(aes(colour=factor(y)),show.legend = FALSE, alpha = 4/10) +
scale_color_manual(values = c(colorn,colory)) +
theme(axis.line=element_blank(),
panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),plot.background=element_blank()) +
ylim(0, 100000) +
labs(x = "Age Group 2")
g3 <- ggplot(data_age3, aes(age, balance)) +
geom_point(aes(colour=factor(y)),show.legend = FALSE, alpha = 4/10) +
scale_color_manual(values = c(colorn,colory)) +
theme(axis.line=element_blank(),
panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
panel.grid.minor=element_blank(),plot.background=element_blank()) +
ylim(0, 100000) +
labs(x = "Age Group 3")
grid.arrange(g1, g2, g3, nrow = 3)
